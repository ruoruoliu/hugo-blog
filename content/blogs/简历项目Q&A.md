---
title: 简历项目Q&A
date: 2026-01-21
tags:
draft: false
---
# 字节跳动-懂车帝（2023.11-2025.4）
--- 
## 懂车帝AI助手懂咔咔项目

> [!NOTE] 构建具有专业汽车知识及工具辅助功能的多轮对话AI助手
> - 多轮对话Query改写与扩展以及实体（车系/车款）识别，改写准确率达91\%，车系识别f1指标达91\%,车款识别f1指标达82\%，配合召回侧增强召回内容准确性和丰富性
> - 构建多轮对话意图需求一二级分类体系，基于大模型prompt打标构建训练数据集，分类准确率达89.2\%，拒答率下降77\%，业务需求支持选车卡片等多种工具辅助功能
> - 针对特定选车场景，设计构建并迭代多轮Memory模块，实现选车标签识别能力，模型线上准确率达83\%，支持新车和二手车选车业务多轮对话能力接入
> - 在多轮对话最终回复效果上与标注团队精细打磨，并进行汽车领域知识和回复样式风格模型微调，在与Base模型的汽车领域多轮对话SBS评估中整体正向6\%

背景：
- 懂车帝C端大模型尝试，在app中加入口，解决用户汽车领域问题，在app中多个页面连接大模型回复功能
- 大模型基座训练&应用，我们负责应用，应用大模型sft训练及基于rag的整体对话链路的算法部分

技术细节：
- 由于首字延迟问题，希望全链路除了回复模型采用参数较大的模型（100B左右），其他均采用bert或者lite版本的模型（13B）
- 多轮改写：
	- 主要解决指代消解、主题和属性省略、以及表述标准化（价格/多少钱/贵不贵）等问题，改写query给下一步做rag召回使用
	- 基于GPT4构造多轮对话及改写query，改写query（主query）拆分多个子query
	- 主query包含完整信息，走意图判断；如果需要，全部query同时并发召回
	- 改写准确率91%，主query和子query拆分都正确
- 实体识别：
	- 最终用于品牌、车系、车款识别，替代原本懂车帝的da
	- ner使用bert+global pointer，识别start和end，处理一下嵌套
	- 识别出实体后，做检索召回，属性包括年款（25款、新款）、车类型（自动、手动）等，然后根据字短匹配规则返回，整体车系f1在90，车款f1在78左右
- 意图识别：
	- router的概念，对不同意图的回复策略不同
	- 比如查参配信息（价格、轴距）就更看重事实性，直接查参数库
	- 对比类，就需要识别多个车款，然后进行全方位的对比
	- 泛知识类，就依赖文章内容做rag
	- 对话类，不用走rag，可以响应速度更快
	- 某些类别也是一些前端样式的触发器，比如卡片、新闻链接、创作者
	- 基于大模型prompt生成百万量级训练数据，训练bert
		- prompt分为粗筛和精筛：粗筛用一个prompt找所有类别，精筛对每一个类别写一个prompt，在测试集上迭代，88左右的整体f1
- memory模块：
	- 基于选车类别query才生效，存选车意图memory，其他类型对话只走working memory（最大32轮对话，不压缩）
	- memory以json字典方式保存，在一个session中存在，不跨session，支持增删改操作
	- 包含固定几个字段，比如品牌，类型，用车需求等，字段内容基于用户app原始选车字段，保持尽可能一致，可以复用app选车逻辑
	- 训练一个lite模型基于对话内容更新memory字典，数据基于线上app选车日志用大模型生成
	- 基于更新的memory字典识别具体字段内容，走选车逻辑（召回同学负责），出选车卡片
- 模型sft
	- 基本只做格式（回复长短）、风格化（比如对车辆介绍的分点）以及对召回内容权威性/时效性判断方面上的sft，保证以markdown格式输出一些内容
	- 拒绝采样（人工标注负例）的方法来筛选训练数据
- 追问使用lite模型直接生成三个下一步可能的问题
	- 按意图类别统计了用户下一个问题的意图分布，基于这个分布生成的问题
	- 后期有专门同学做召回排序了，但是不清楚具体细节了
- 评估&指标：
	- 每周都会有标注同学基于线上结果和豆包进行整体sbs打分，同时在事实性（改写query/召回/幻觉/模型选择错误等）、相关性、用户体验等方面进行标注，每周50q，24年中达到6%正向
	- 线上dau从一开始10w，涨到50w左右，但是轮次很低，主要由于入口在搜索的占比不小，年中后开始减少投入
## 懂车帝用户增长Push策略

> [!NOTE] 基于uplift的付费push策略
通过Uplift模型建模用户对Push条数敏感度，基于Treatment条数设计Push规划策略，在Vivo品牌上验证带来6.77\%DAU增长，较大提升广告与线索收益

背景：
- c端大模型业务收缩，转入用户增长团队，做push
- push的业务知识
	- 不同品牌发送条数不同，发送时间间隔不同（半小时/一小时）
	- push主要有条数模型和时机模型来控制
		- 通过uplift值判断每个用户的最优规划条数
		- 通过用户每个小时的点击率，规划最优发送时间表（哪个小时发）
- vivo业务有运营付费条数（年包）：单设备发送2条免费后，可以继续发，点击后付费，需要有个策略，在预算下怎么发能收益最大（dau）

技术细节：
- 训练uplift模型，判断用户对发送条数的敏感度，即多少条后用户成为dau
	- 样本收集：开样本收集实验，每个用户选择一种条数，固定发
	- 模型为s-learner，基础用户特征+treatment（条数）作为输入，二分类问题
- 离线规划：
	- uplift模型预估每个用户不同条数dau分数
	- 时机模型计算每个用户不同条数下的规划，从而确定付费预估（除前2条外的点击率和）
	- 带约束规划问题求解：
		- 约束为总预算（硬性要求）和人均条数（自驱要求）
		- 最大化dau
	- 得到规划结果后，写入hive表，再通过kafka写入设备正排，第二天按规划push

指标：
- push拉活率+4%，dau+0.7%
- vivo push拉活率+40%，dau+6.8%
- 设备点击率、人均发送、到达、点击均正向
- 推全日均收益19000元

# 腾讯-腾讯视频（2019.9-2023.5）
--- 
## 腾讯视频标准化

> [!NOTE] 视频标签识别
从零开始构建融合基于Bert模型多分类和基于向量召回+倒排检索结合相关性两套策略的标签识别系统，并进一步利用标签相互关系及层级关系提升识别效果。在千级别标签体系中，周均f1指标71\%提升至75\%，服务腾讯视频下游推荐搜索业务场景

背景：
- 腾讯视频每天几十万入池视频，对于低等级视频需要自动打标，需要视频标签识别系统

技术细节：
- 整体方案：end2end+标签召回打分
	![image.png](https://images.ruoruoliu.com/2026/01/756ebed4ea51bf44f970bb45c91b6a05.png)
- end2end：
	- 模型结构：bert底座，与标签特征交互，n个head的二分类任务
	- 特征：包括title、描述、视频向量特征、asr/ocr、创作者特征等
	- 加入多目标（视频分类）：分类label有ground truth作为训练，线上预测没有
	- 模型结构加入一二级标签分类预测（每个标签有自己的一二级分类），希望预测一级和二级尽量吻合，最终loss加权和作为整体loss
- 标签召回打分：
	- 目的：充分利用标签信息（文本、层级关系、向量等）
	- 三路召回：文本召回（es）、创作者召回、视频向量召回，top20召回覆盖率96%
	- 相关性模型：bert底座，二分类任务
- 两路分数加权融合最终识别结果
指标：
- f1 60->75

## 腾讯视频搜索Sug场景及社区弹幕场景优化

> [!NOTE] 搜索Sug场景
在原有DNN排序模型优化的基础上添加后验条件概率召回融合模块，首次为该场景排序模型设计并引入用户画像和相关匹配特征，实现个性化候选展示。使Sug模块点击率提升8.7\%, 平均点击位置减少16.9\%，大幅提升用户搜索效率

![image.png|500](https://images.ruoruoliu.com/2026/01/7fdfc5acaf3cde9b7a745229d5c1f632.png)

背景：
- 转入搜索团队，sug搜索入口占比超50%，很重要
- 负责sug模块业务指标迭代

技术细节：
- 整体逻辑是召回+排序
- 召回：
	- 包括精品doc、人名、热榜、运营、querylog
	- 召回逻辑
		- 原始的sug召回引擎，可以看成是es逻辑，前缀+关键词等
		- 加入后验统计策略召回，基于时间衰减
		- querylog天级别臆造、qc流程，语义重复很难处理（xxx中文完整版 和 xxx中文版）
- 排序
	- 日志拼接特征，小时级更新sug rank模型
	- 特征重要度分析和整理
	- 曝光位置作为训练特征不合适，下线后有线上收益
		- 原因：sug固定窗口且严格排序，推荐场景滑动窗口且多样性打散
	- 特征除了query侧、doc侧外，加入用户画像特征，
		- 用户侧（用户时长、品类、基础画像、行为聚类）
		- 用户和doc的match（标签相关）
- 后处理：
		- 数据源之间的归一化、去重逻辑
		- 运营干预逻辑，黑白名单

指标：
- sug点击率：相对提升8.7%
- 平均点击位置：相对降低16.9%

> [!NOTE] 社区弹幕场景
为腾讯视频弹幕排序打通离线和在线特征链路，引入DNN模型排序能力，结合弹幕前端样式优化排序，弹幕互动率提升60\%、人均点赞次数提升77\%，点赞渗透率达到业界领先

背景：
- 从统计排序到支持DNN模型排序，打通链路
- 前端样式主要是弹幕样式的一些工程策略优化

## 文本生成能力探索及AIGC应用落地

> [!NOTE] 视频标题风格改写
在Seq2Seq结构基础上探索多种实体词拷贝机制，对视频标题进行风格改写。通过单边预训练、BPE分词、引入标签特征等手段优化指标，人工采纳率提升至89\%，大幅节省标准化成本

![image.png|500](https://images.ruoruoliu.com/2026/01/35e2a2239875e3676f8e2294da636822.png)

背景：视频标题风格改写，把教学类视频的标题进行改写，提升采纳率，降低人工成本

技术细节：
- seq2seq模型，baseline版本容易出现实体词缺失
- bpe分词解决低频实体词词表unk问题
	- bpe逻辑：从单char开始，不断按统计概率把子词连接为新子词，直到词表达到指定大小
- seq2seq预训练：
	- encoder引入视频标题分类任务
	- decoder引入mlm任务（masked lm），随机和实体词掩码
- seq2seq训练：
	- encoder引入标签特征，方便模型快速找到相关实体
	- 高频句式loss权重衰减，基于beam search的topN+策略筛选，防止多样性缺失
	- 模型结构尝试
		- copynet：每个token判断是应该拷贝还是生成，拷贝就从source里选，然后把两个概率（某个词的拷贝概率和生成概率）相加
			![image.png|400](https://images.ruoruoliu.com/2026/01/610c9c2c685e618fdaced643ccd33001.png)
		- pointer generator：类似，利用attention来完成拷贝词的选择
			![image.png|400](https://images.ruoruoliu.com/2026/01/a8b9508b0fb95c63c914fc4fa4a88ae0.png)

指标
- 评测集1000条
- 线上日均6000+视频，人工采纳率73到89，节省20%成本


> [!NOTE] 对话模型定制
收集业务方人设语料，通过prompt生成风格化对话语料，基于DeepSpeed框架进行10B量级对话模型人设与风格的Post-Training

背景：游戏业务方希望对话语料风格化，基于prompt构造风格化对话语料，进行sft训练

# 搜狗-输入法（2016.9-2019.9）
--- 
## 输入法用户词预测功能

> [!NOTE] 词预测
优化LSTM/GRU及变种RNN深度语言模型指标及推断速度，为搜狗输入法首次提供线上基于深度模型的用户词预测功能，线上服务点击率提升1.2\%

## 输入法智能回复(句联想)功能

> [!NOTE] 句联想
通过搜狗对话语料构建高相关性多轮对话训练数据，基于Seq2Seq模型并构造基于损失的意图多样性模块，从零实现输入法智能回复功能, 服务使用率从4.7\%提升至10.3\%